{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Slot_Filling_(GRU).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPO-DukreCmT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww5PkWEJbUed"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1_Y5cKUrCs8r9ZiVfzmgpfJJOQum_we39)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VSKP66bA23x"
      },
      "source": [
        "import json\n",
        "\n",
        "def read_json_file (PATH):\n",
        "\n",
        "  f = open (PATH, \"r\")\n",
        "\n",
        "  # Reading from file\n",
        "  data = json.loads(f.read())\n",
        "  data = data['rasa_nlu_data']\n",
        "  data = data['common_examples']\n",
        "\n",
        "  sentences = []\n",
        "  indexes = []\n",
        "  labels = []\n",
        "\n",
        "  # Iterating through the json\n",
        "  for sample in data:\n",
        "      sentences.append(sample['text'])\n",
        "      index = []\n",
        "      label = []\n",
        "      \n",
        "      # extract the start and end tokens of each entity with the corresponding label within the sentence\n",
        "      for elem in sample['entities']:\n",
        "        index.append((elem['start'], elem['end']))\n",
        "        label.append(elem['entity'])\n",
        "\n",
        "      indexes.append(index)\n",
        "      labels.append(label)\n",
        "\n",
        "  # Closing file\n",
        "  f.close()\n",
        "  return sentences, labels, indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gocs_7zJLdc6"
      },
      "source": [
        "import re\n",
        "\n",
        "# In this function we iterate over tokens of an input sentence and finds label of them\n",
        "def find_label_of_sequences(sentences, labels, indexes):\n",
        "  seq_tags = []\n",
        "  \n",
        "  for sent, label, index in zip (sentences, labels, indexes):\n",
        "    # find start token of each word within the input sentence\n",
        "    res = [ele.start() for ele in re.finditer(r'\\S+', sent)]\n",
        "    word_index = 0\n",
        "    # initialize the label of all of the tokens with 'O' for sentence 'sent'\n",
        "    seq_label = [tags2index['O'] for i in range(0, len(res))]\n",
        "    # iterate over each word of the sentnce \n",
        "    for elem in res:\n",
        "      tag_index = 0\n",
        "      # check whether the token exists in one of the time_slot indexes\n",
        "      for tag in index:\n",
        "        if elem == tag[0] or (elem < tag[1] and elem > tag[0]):\n",
        "          # update the label of 'word_index' token to its label \n",
        "          seq_label[word_index] = tags2index[label[tag_index]]\n",
        "        tag_index += 1\n",
        "      word_index+=1\n",
        "    seq_tags.append(seq_label)\n",
        "  return seq_tags\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zILIBrTdPB0"
      },
      "source": [
        "import re\n",
        "sent='what flights are available from pittsburgh to baltimore on thursday morning'\n",
        "tmp = [ele.start() for ele in re.finditer(r'\\S+', sent)]\n",
        "print(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0E7ALMqaAjl"
      },
      "source": [
        "TRAIN_PATH = \"/content/drive/MyDrive/dataset/ATIS/train.json\"\n",
        "TEST_PATH = \"/content/drive/MyDrive/dataset/ATIS/test.json\"\n",
        " \n",
        "sentences_train, labels_train, indexes_train = read_json_file(TRAIN_PATH)\n",
        "sentences_test, labels_test, indexes_test = read_json_file(TEST_PATH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyCzx1EbgwUF"
      },
      "source": [
        "unique_tags = ['O']\n",
        "\n",
        "total_labels = labels_train + labels_test\n",
        "\n",
        "for labels in total_labels:\n",
        "  for label in labels:\n",
        "    unique_tags.append(label)\n",
        "\n",
        "unique_tags = set(unique_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC56X1KDj_9q"
      },
      "source": [
        "n_tags = len(unique_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWszYi7MwY7d"
      },
      "source": [
        "n_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8RlOziWjKoe"
      },
      "source": [
        "tags2index = {t:i for i,t in enumerate(unique_tags)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da4vPeYwt2m5"
      },
      "source": [
        "tags2index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqGcuMbekGB0"
      },
      "source": [
        "seq_tags_train = find_label_of_sequences(sentences_train, labels_train, indexes_train)\n",
        "seq_tags_test = find_label_of_sequences(sentences_test, labels_test, indexes_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJNq1YVRlpEE"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences_train+sentences_test)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crrVhDZ0kgNj"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkcXK4mwnfem"
      },
      "source": [
        "sent_length = {}\n",
        "\n",
        "for elem in X_train:\n",
        "  res = len(elem)\n",
        "  if res in sent_length:\n",
        "    sent_length[res]+=1\n",
        "  else:\n",
        "    sent_length[res]=1\n",
        "\n",
        "print(sent_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfPCqf1vhdxc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [key for key in sent_length]\n",
        "y = [sent_length[key] for key in sent_length]\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyAsXD0KfaCt"
      },
      "source": [
        "max_len = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puRLdm_74yYN"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_u8ga5EnTCU"
      },
      "source": [
        "X_train[2], seq_tags_train[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLAsyMr6l6tD"
      },
      "source": [
        "seq_tags_train = pad_sequences(seq_tags_train,  padding='post', maxlen=max_len, value=tags2index[\"O\"])\n",
        "seq_tags_test = pad_sequences(seq_tags_test,  padding='post', maxlen=max_len, value=tags2index[\"O\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jko_lR98kTld"
      },
      "source": [
        "seq_tags_train = seq_tags_train.reshape(seq_tags_train.shape[0], seq_tags_train.shape[1], 1)\n",
        "seq_tags_test = seq_tags_test.reshape(seq_tags_test.shape[0], seq_tags_test.shape[1], 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saKpcFo3fLa9"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, GRU\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, \n",
        "                           output_dim=embedding_dim, \n",
        "                           input_length=max_len,\n",
        "                           trainable=True))\n",
        "\n",
        "model.add(Bidirectional(GRU(300, dropout=0.2,  return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOqB-QSskx5D"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIaKanb6fgFu"
      },
      "source": [
        "# https://stackoverflow.com/questions/58565394/what-is-the-difference-between-sparse-categorical-crossentropy-and-categorical-c\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAlGlkCGk0SZ"
      },
      "source": [
        "batch_size = 32\n",
        "import numpy as np\n",
        "\n",
        "history = model.fit(np.array(X_train), seq_tags_train, validation_data=(np.array(X_test), seq_tags_test),\n",
        "                    batch_size=batch_size, epochs=6, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--9BZAgBojgs"
      },
      "source": [
        "pred = model.predict(np.array(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J71uUiTXovvY"
      },
      "source": [
        "np.shape(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC1waS3LrtjQ"
      },
      "source": [
        "pred = pred.reshape(pred.shape[0]*pred.shape[1], pred.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZIR3WXOo0NE"
      },
      "source": [
        "np.shape(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILGuKWMOr_qM"
      },
      "source": [
        "predicted_label = [np.argmax(elem) for elem in pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL48U9v5rcJu"
      },
      "source": [
        "test_label = seq_tags_test.reshape(seq_tags_test.shape[0]*seq_tags_test.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l6ovDvLqbaz"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(predicted_label, test_label))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}