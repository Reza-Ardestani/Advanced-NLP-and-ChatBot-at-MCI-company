{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFp8caUmP8R1",
    "outputId": "0b270a4e-ac4d-4833-8ed5-47b4fe186b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
      "To: /content/train.txt\n",
      "100% 9.87M/9.87M [00:00<00:00, 240MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy\n",
      "To: /content/test.txt\n",
      "100% 5.80k/5.80k [00:00<00:00, 11.0MB/s]\n",
      "108\n",
      "188364\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!gdown --id 1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
    "!gdown --id 1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy\n",
    "\n",
    "def read_file(input_file_address):\n",
    "    lines = []\n",
    "    with open (input_file_address , 'r', encoding=\"UTF-8\") as f :\n",
    "        for line in f.readlines():\n",
    "            if (len(line.split(' ')) > 3):\n",
    "                lines.append(line)\n",
    "    return lines\n",
    "\n",
    "train_set = read_file('/content/train.txt')\n",
    "test_set = read_file('/content/test.txt')\n",
    "\n",
    "print(len(test_set))\n",
    "print(len(train_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiPMLdVARZBJ"
   },
   "source": [
    "# Q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6il9BlUNSaMT",
    "outputId": "24c5dbba-aff5-4716-f428-e7e147d182c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "چون مشک سیه بود مرا هر دو چشم\n",
      "چون مشک سیه بود مرا هر دو چشم من\n",
      "----------------\n",
      "گر خورد سوگند هم آن را\n",
      "----------------\n",
      "زانک نفس آشفته تر گردد از آن\n",
      "----------------\n",
      "ازین زشت تر در جهان رنگ و\n",
      "----------------\n",
      "دوست در خانه و ما گرد و\n",
      "دوست در خانه و ما گرد و از\n",
      "----------------\n",
      "شب‬‫ است‬ ‫و‬ ‫شمع‬ ‫و‬ ‫شراب‬ و از\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# The added number shows the number of guesses for each sentences\n",
    "test_dataset = [\n",
    "                \"2 چون مشک سیه بود مرا هر دو\",\n",
    "                \"1 گر خورد سوگند هم آن\",\n",
    "                \"1 زانک نفس آشفته تر گردد از\",\n",
    "                \"1 ازین زشت تر در جهان رنگ\",\n",
    "                \"2 دوست در خانه و ما گرد\",\n",
    "                \"1 شب‬‫ است‬ ‫و‬ ‫شمع‬ ‫و‬ ‫شراب‬ و\"\n",
    "                ]\n",
    "\n",
    "#Calculate count of unigrams\n",
    "def calculate_unigram(input_file_address):\n",
    "\n",
    "    unigrams_dict = {}\n",
    "    lines = read_file(input_file_address)\n",
    "    for line in lines:\n",
    "        line  = ' '.join(line.split())\n",
    "        words = [word.strip() for word in line.split(' ')]\n",
    "        for word in words:\n",
    "            if word in unigrams_dict.keys():\n",
    "                unigrams_dict[word] += 1\n",
    "            else:\n",
    "                unigrams_dict[word] = 1\n",
    "    return dict(sorted(unigrams_dict.items(),\n",
    "                       key=lambda item: item[1], reverse=True))\n",
    "\n",
    "unigrams = calculate_unigram('/content/train.txt')\n",
    "\n",
    "#Calculate count of bigrams\n",
    "def calculate_bigram(input_file_address):\n",
    "\n",
    "\n",
    "    bigrams_dict = {}\n",
    "    lines = read_file(input_file_address)\n",
    "\n",
    "    for line in lines:\n",
    "        line  = ' '.join(line.split())\n",
    "        words = [word.strip() for word in line.split(' ')]\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = (words[i],words[i + 1])\n",
    "            if bigram in bigrams_dict.keys():\n",
    "                bigrams_dict[bigram] += 1\n",
    "            else:\n",
    "                bigrams_dict[bigram] = 1\n",
    "    return dict(sorted(bigrams_dict.items(),\n",
    "                       key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "bigrams = calculate_bigram('/content/train.txt')\n",
    "\n",
    "mu = 0.01\n",
    "p_background = 1/len(unigrams.items())\n",
    "\n",
    "def complete_sentence(test_set: list):\n",
    "    for sentence in test_set:\n",
    "        new_dict = {}\n",
    "        sentence = ' '.join(sentence.split())\n",
    "        words = [word.strip() for word in sentence.split(' ')]\n",
    "        number_of_guess = words[0]\n",
    "        \n",
    "        words = words[1:len(words)]\n",
    "        \n",
    "        for i in range(int(number_of_guess)):\n",
    "            \n",
    "            for key, value in bigrams.items():\n",
    "                if key[0].strip() == words[len(words)-1].strip():\n",
    "\n",
    "                    #bigram probability based on drichlet prior model\n",
    "                    new_dict[key] = value + (mu * p_background)/unigrams.get(key[0]) + mu\n",
    "\n",
    "            sorted_list = list(sorted(new_dict.items(), \n",
    "                                      key=lambda item: item[1], reverse=True))\n",
    "            \n",
    "            print(' '.join(words) + ' ' + sorted_list[0][0][1])\n",
    "\n",
    "            #Add the word with the most probability to the sentence\n",
    "            words = words + [sorted_list[0][0][1]]\n",
    "        print('----------------')\n",
    "\n",
    "complete_sentence(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uhzf1ZlHRaOh"
   },
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2Lpj7RIdtQd",
    "outputId": "79db150e-cdb6-4c07-eabe-2b852d5a1e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in test set : 872\n",
      "Number of sentences in test set : 108\n",
      "perplexity of model is : 2626.1926199715494\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "def bigram_prob_drichlet_prior(test_set: list):\n",
    "\n",
    "    # the probability of all sentences in test dataset\n",
    "    total_probability = 0\n",
    "\n",
    "    # the number of all words with frequencies in train dataset\n",
    "    all_freq = sum(unigrams.values())\n",
    "\n",
    "    #N in perplexity formula (number of words in test dataset)\n",
    "    number_of_words = 0\n",
    "    \n",
    "    # parameter of model\n",
    "    mu = 0.01\n",
    "\n",
    "    # V vocabulary size of model (unique words in train dataset)\n",
    "    vocalbulary_size = len(unigrams.items())\n",
    "    \n",
    "    # background probability for drichlet prior model\n",
    "    p_background = 1/vocalbulary_size\n",
    "    \n",
    "    sentence_size = 0\n",
    "    \n",
    "    for sentence in test_set:\n",
    "        sentence = ' '.join(sentence.split())\n",
    "        words = [word.strip() for word in sentence.split(' ')]\n",
    "        number_of_words = number_of_words + len(words) + 1\n",
    "        sentence_size = sentence_size + 1\n",
    "        \n",
    "        # probability of first word\n",
    "        sentence_probability = unigrams.get(words[0])/all_freq\n",
    "        for i in range(len(words)-1):\n",
    "            word = words[i]\n",
    "            bigram = (words[i], words[i+1])\n",
    "\n",
    "            if bigram not in bigrams.keys():\n",
    "                bigram_count= 0\n",
    "            else:\n",
    "                bigram_count = bigrams.get(bigram)\n",
    "            \n",
    "            if word not in unigrams.keys():\n",
    "                unigram_count = 0\n",
    "            else:\n",
    "                unigram_count = unigrams.get(word)\n",
    "\n",
    "            # used logarithm base 2 for calculating sum of probability\n",
    "            sentence_probability = sentence_probability + math.log2(((bigram_count + (mu * p_background)))/(unigram_count + mu))\n",
    "        \n",
    "        total_probability = total_probability + sentence_probability\n",
    "\n",
    "    perplexity = math.pow(2, -1*(total_probability/number_of_words))\n",
    "    print(f'Number of words in test set : {number_of_words}')\n",
    "    print(f'Number of sentences in test set : {sentence_size}')\n",
    "    return perplexity\n",
    "\n",
    "perplexity = bigram_prob_drichlet_prior(test_set)\n",
    "print(f'perplexity of model is : {perplexity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZF1A0ToRsGs"
   },
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERvtavKrFU7h",
    "outputId": "4c8e072b-cc46-4d1a-c2a9-983b481da6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 930464\n"
     ]
    }
   ],
   "source": [
    "# Extract sequences of 3-grams from corpus\n",
    "\n",
    "# count of given words to predict the next word\n",
    "window_size = 2\n",
    "\n",
    "# length of sequence or n-gram\n",
    "seq_length = window_size + 1\n",
    "\n",
    "# store the n-grams in sequences list\n",
    "sequences = list()\n",
    "\n",
    "# extract a sentence of each 'seq_length' consecutive words from given sentences.\n",
    "for sentence in train_set:\n",
    "     line  = ' '.join(sentence.split())\n",
    "     words = [word.strip() for word in line.split(' ')]\n",
    "     for i in range(seq_length, len(words) + 1):\n",
    "         seq = words[i-seq_length:i]\n",
    "         line = ' '.join(seq)\n",
    "         sequences.append(line)\n",
    "\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "960MSh4TISvx"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# create the tokenizer and fit it on the input text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "\n",
    "# tokenize the sequences into encoded numbers\n",
    "sequences = tokenizer.texts_to_sequences(sequences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "H1yaB8JNI9kP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sequences = array(sequences)\n",
    "\n",
    "# split the sequence of N-grams into input (x) and output (y)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.04, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WEUdKTAeVIWT"
   },
   "outputs": [],
   "source": [
    "# The PlotLosses function, plots the validation and training loss function during the\n",
    "#  training to give an insight of training the model\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "  \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YXRA7fZpcDAn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "#Generator class \n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "batch_size = 1000\n",
    "train_generator = CustomDataGen(X_train, y_train, batch_size)\n",
    "validation_generator = CustomDataGen(X_validation, y_validation, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "sOD2JOo6Cq1a",
    "outputId": "83ac265c-b404-457d-9616-962ccd93243b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "893/893 [==============================] - 622s 696ms/step - loss: 6.3618 - accuracy: 0.1034 - val_loss: 7.1035 - val_accuracy: 0.0898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5364f2fa90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load dependencies\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=window_size, name ='Embedding-layer'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(int(vocab_size/10), activation='relu', name='hidden-layer'))\n",
    "model.add(Dense(vocab_size, activation='softmax', name='output-layer'))\n",
    "\n",
    "# print summary of model's structure:\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 3\n",
    "checkpoint_filepath = \"/content/drive/MyDrive/models/model1.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(train_generator, \n",
    "          batch_size=batch_size, \n",
    "          epochs=EPOCHS, \n",
    "          steps_per_epoch=X_train.shape[0]/batch_size,\n",
    "          validation_data=validation_generator,\n",
    "          callbacks=[model_checkpoint_callback, plot_losses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6NxYs_yPCvw"
   },
   "source": [
    "This model was overfitted, but because of the lack of resources I couldn't tune the model and train it again. So the predicted words for next part are also not good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUSzjuUgSZqs",
    "outputId": "1502add3-1e63-4443-ca88-6edf13df4d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "هر دو  : جهان\n",
      "هم آن  : را\n",
      "گردد از  : آن\n",
      "جهان رنگ  : و\n",
      "ما گرد  : و\n",
      "‫شراب‬ و  : در\n"
     ]
    }
   ],
   "source": [
    "#predicting the next word for these sentences\n",
    "\n",
    "test_dataset = [\n",
    "                \"چون مشک سیه بود مرا هر دو \",\n",
    "                \"گر خورد سوگند هم آن\",\n",
    "                \"زانک نفس آشفته تر گردد از\",\n",
    "                \"ازین زشت تر در جهان رنگ\",\n",
    "                \"دوست در خانه و ما گرد\",\n",
    "                \"شب‬‫ است‬ ‫و‬ ‫شمع‬ ‫و‬ ‫شراب‬ و\"\n",
    "                ]\n",
    "\n",
    "\n",
    "sequences = list()\n",
    "\n",
    "for sentence in test_dataset:\n",
    "     line  = ' '.join(sentence.split())\n",
    "     words = [word.strip() for word in line.split(' ')]\n",
    "     seq = words[len(words)-2:len(words)]\n",
    "     line = ' '.join(seq)\n",
    "     sequences.append(line)\n",
    "\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "sequences = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "sequences = array(sequences)\n",
    "X = sequences[:,:]\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "best_model_path = '/content/drive/MyDrive/models/model1.h5'\n",
    "model.load_weights(best_model_path)\n",
    "\n",
    "predicted = model.predict(X)\n",
    "\n",
    "# given the ID of word returns its corresponding word\n",
    "def convert_ID_to_word(ID):   \n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if (index == ID).any() :\n",
    "      return word\n",
    "  return \n",
    "\n",
    "# given the input sentence as an array of word Ids, returns the string of sentence\n",
    "def get_sentence_from_IDs(x):\n",
    "  sent = ''\n",
    "  for elem in x:\n",
    "    sent+= convert_ID_to_word(elem) + ' '\n",
    "  return sent\n",
    "\n",
    "# print the test data with prediction of model\n",
    "for i in range(X.shape[0]):\n",
    "    print( get_sentence_from_IDs(X[i]) +' : '+convert_ID_to_word(np.argmax(predicted[i])))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2-MahsaKhoshnoodi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
